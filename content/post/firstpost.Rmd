---
title: "Can we predict the 2018 Champion's League winner?"
subtitle: Don't bet your savings!
date: '2018-05-10'
tags:
- Soccer
- Regression
- Prediction
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## Introduction
Football is the leader sport in [31 out of the 51 countries](https://www.snack-media.com/2016/05/how-popular-is-football-around-the-world/) in Europe and to avoid putative misunderstanding with our American readers, I mean soccer amigos. Europeans express their love for football in various and diverse ways, most of them accompanied with alcohol and flatbread Italian delicacies. But we are not here to judge, we are here to make money (well, try to make money at least). 

I hate to admit that this post is not scientifically motivated. Invoking our inner nerds (dude let's not elaborate on that, to come to the point and read this post, you must be a nerd) we all reminisce moments when our obsessed-with-football-betting dad asked us for a scientific advice on which team will win. 

There several ways to reply to a request like that: 

- you can refuse to make a prediction (been there but this is a subject of a more sentimental post)
- you can take a random guess (for the unlucky nerds I think the 0.33 probability is a no go) 
- you can let nerds with hardly any social skills, do it formally for you. 

If you are here, you are probably smart enough to choose the last option, which spares you hours of literature review, data searching, coding and many other activities that ensure that we will die alone, hoping that the result was worth the effort.


After some research, we discovered this annual football competition called UEFA Champion's league that attracts a lot of football fan attention. For us football ignorant nerds, you can think of Champion's League as the annual ISBA^[International Society of Bayesian Statistics -- the one that asks for contributions for mantaining Reverend Bayes tomb in mint conditions, no joke] conference where non-EU based professors are not allowed to participate (I know ISBA without Gelman is like garlic sauce without garlic). Professors (Barcelona, Liverpool etc) and young researchers (Dynamo Kiev, Benfica etc) are then called to compete one another by presenting cool but time consuming MC samplers (INLA rocks!). 

The winner then gets the **European Bayes League trophy** and a publication with discussion on JRSS-B! 

This already sounds amazing but to make it more spicy, PhD students could support their favourite Bayesian professor/young researcher by betting their scholarship money on him/her. We cannot help but wonder, where should these poor, food-deprived, frustrated and with an apparent gambling addiction PhD student put their money on?


We are not delusional (although we wait patiently for our significant other to come and save us from this world's misery riding Drogon), we know we are not the first attempted this and we acknowledge the complexity of the issue. In general the Poisson distribution is the most common approach for modelling the number of goals in a football match. (Probably mean) Statisticians have observed a relatively low correlation between the number of goals scored by the two teams (that of course needs to be taken into account), and this is where the cornucopia of random effects began, you can check [Karlis & Ntzoufras](https://s3.amazonaws.com/academia.edu.documents/8134872/03_karlis_ntzoufras_2000_student_final_scanned.pdf?AWSAccessKeyId=AKIAIWOWYYGZ2Y53UL3A&Expires=1525613609&Signature=lnvcvnFiLAJSut01PEX5FsY9HqU%3D&response-content-disposition=inline%3B%20filename%3DO11_Modellirig_Soccer_Data.pdf) and, as any student who's fighting with bibtex would say, the references therein. [Karlis & Ntzoufras](https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/1467-9884.00366) (same authors, different paper) used a bivariate Poisson with a series of random effects and modelled the Italian Serie A data for 1991-1992 and the Champions League data for the 2000-2001 season. [Rue & Salvesen](https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/1467-9884.00243) used data from the English Premier League and suggested a Bayesian dynamic GLM to predict the next week-end's score. [Baio & Blangiardo](https://www.tandfonline.com/doi/abs/10.1080/02664760802684177) extended the model suggested by Karlis & Ntzoufras (the second one), proposed a hierarchical Bayesian approach (which is of course cooler than the EM & maximum likelihood, but not data drivHAHAHAHA) and tested its performance using the Italian Serie A championship 2007-2008. 

Our approach is neither novel nor constists of a pleathora of random effects. We had plenty of time the past month (if you are my supervisor read: I have been working solely on the grant till midnight for the past month) and decided to apply Baio & Blangiardo's model to this years' Champion's League data. This year's final four consisted of Liverpool, Roma, Bayern and Real. Our **GOAL** (see what i did there?) is using 2018 Champion's League data to predict the 2018 Champion's League winner and get an estimate about the final score. 

## Methods
From a statistical standpoint, the result of a football match $g$ is a bivariate random variable $(Y_{g,H},Y_{g,A})$ representing the goals scored by the Home Team $Y_{g,H}$ and those scored by the Away Team $Y_{g,A}$. Yes, you ***may*** think that this is a sad way of seeing the world.

As always with count data, our first guess is that both variables are Poisson distributed, i.e. $Y_{g,T}\sim \text{Poisson}(\theta_{g,T})$. The parameters of these Poisson distributions, the scoring intensities $\theta_{g, H}$ and $\theta_{g,A}$, depend on how strong in attack is the team whose goals we are counting and how bad in defence is their adversary. There is no doubt about that, but there are several different ways of materializing this intuition. 

In the most trivial model, the random effects (or latent variables, depending on what's trendier at the moment) representing the strength in attack and defence of each team are assumed to stay the same through-out the whole competition. This is a rather strong assumption judging by the Liverpool performance at the first semi-finals against Roma. But again, we warned you "Don't bet your savings". In formulas this assumption translates to:

\[ \begin{cases} \log\theta_{g,H} = \text{home} + \text{attack}_{H(g)} + \text{defence}_{A(g)} \\
\log\theta_{g,A} =  \text{attack}_{A(g)} + \text{defence}_{H(g)}
\end{cases}\]

where $H(g)$ and $A(g)$ are indices specifying the Home and the Away team at game $g$. The models for the two teams are not symmetrical because we know that playing home has a positive effect on the home-team's performance. This may be the time where the ISBA comparison starts to wabble: I have always thought that for a socially awkward academics it may be easier to give a talk in front of a bunch of strangers rather than embarrassing themselves in front of their friends (but this may also be material for another, rather personal, post).

In terms of priors (and although this is a discussion that could last a lifetime I will keep it quick), we used skeptical (i.e. mean $0$) but non-informative (i.e. precision $0.01$) Gaussian priors for all random effects.


## Results

Before having a look at the first results, keep in mind that we started the analysis before the results of the first semi-finals. By the time we got model running and had a first draft, we could add the results of the first semi-finals, and thus update the dataset and compare the predictions. Of course now we know the teams that will compete on the final match (Liverpool and Real Madrid) but for the sake of discussion we will act like we don't know. 

Enough with the babbling, my dad wants to know if the money spent on my education, and the fact that he hasn't seen any grandchild yet is worth it. 

Table 1 shows the expected goals not taking into consideration the first round of semi-finals, whereas Table 2 takes into account the first round of semi-finals. The columns of these Tables show the mean goals and standard deviation scored by each team, and the probability of a win, loose or tie with the corresponding credibility regions. 

Judging by the standard deviation of the H-Team and A-team goals, it would be slightly naive to bet any money on the precise score. Let's give a rough interpretation for the lay audience using the Liverpool vs Roma, result on Table 1. The mean goals Liverpool scores is 2.5 (lets say 3 goals) vs 1 goal for Roma. That gives a score of 3-1. 
Yep, you are right, predicting the 5-2 of Liverpool against Roma was proven our Waterloo (not the Abba one, spoiler alert a Eurovision post will follow)

However there is not much certainty around this result since the model suggests that for Liverpool the goals could easily vary from 0 to 7 and for Roma from 0 to 4 (that is not entirely correct but let's assume it is for the sake of communicating the results). 

The probabilities on these Tables were calculated by taking the posterior difference of the goals per pair, and calculating the probability that this difference is larger (H-Team wins), lower (A-team wins) and equal (Tie) to 0. The probability of Liverpool winning the match with Roma is $P = 0.61$ and (5-2 the real score), $P=0.2$ that Bayern wins Real (1-2 the real score), $P=0.62$ that Real wins Bayern (2-2, the real score) and $P = 0.29$ that Roma wins Liverpool (4-2, the real score). That gives the model 50% success on predicting the winner (yep we know that this estimator can be extremely unstable judging from the $n=4$ sample size). The results after updating the data using first round semi-finals where similar (Table 2). 

```{r}
load("UpdatedTables.RData")

colnames <- c("H-Team", "A-Team", "H-Goal<br/> Mean (sd)", "A-Goal<br/> Mean (sd)", "H-Team wins<br/> P (CI)", 
              "A-team wins<br/> P (CI)", "Tie<br/> P (CI)")
knitr::kable(Tab_1, caption = "Predictions without first round of the semi-finals", 
             col.names =  colnames)
```
```{r}
knitr::kable(Tab_3, caption = "Predictions with first round of the semi-finals", 
             col.names =  colnames)
```

At this point we can say with some evidence that the model in terms of predicting Champion's League results is more or less lousy. A natural extension (that does not require hours of looking for covariates) is to include a random effect that accounts for phase effect. To get an estimate about the semi-finals we needed some data on the semi-finals, thus we used the updated dataset with the first round of the semi-finals. The results again are far from the truth; however it seems that by adding a phase effect, the home team gets an advantage. Just think of the Roma results: (4-1; 3-0) with Barcellona and (5-2, 4-2) with Liverpool. Given this results it seems reasonable that the phase effect turns out to be a home effect. Although far-fetched and marginally overinterpretation with the amount of data available, a possible interpretation of this effect might be that as a team approaches  the Champion's League final, fans tend to be more and more supportive and this support is better reflected on the Home-team. 

```{r}
load("UpdatedTables.RData")

colnames <- c("H-Team", "A-Team", "H-Goal<br/> Mean (sd)", "A-Goal<br/> Mean (sd)", "H-Team wins<br/> P (CI)", 
              "A-team wins<br/> P (CI)", "Tie<br/> P (CI)")
knitr::kable(Tab_2, caption = "Predictions with first round of the semi-finals and phase effect", 
             col.names =  colnames)
```

As far as predicting the champion's league winner, all the possible scenarios are shown on Table 4, with of course Real Madrid looking the most plausible winner. For these results, we excluded the home effect in the final match, since the Champion's League final takes place on "neutral" ground (Ukraine). It is also interesting to compare our results with [the official Champion's League statistics](http://www.uefa.com) for the final, where the probability that Real Madrid or Liverpool wins is $P=0.42$ and $P= 0.33$ respectively, and there is a $P = 0.25$ for a draw (for the first 90 minutes; disregarding extra time and penalties). Interestingly, the probability that Liverpool wins coincides with our model's probability but also with the probability of predicting the results by **randomly guessing**. 

```{r}
load("UpdatedTable_4.RData")

colnames <- c("H-Team", "A-Team", "H-Goal<br/> Mean (sd)", "A-Goal<br/> Mean (sd)", "H-Team wins<br/> P (CI)", 
              "A-team wins<br/> P (CI)", "Tie<br/> P (CI)")
knitr::kable(Tab_4,  col.names =  colnames, 
             caption = "All possible prediction for the Champion's League winner")
```


## Wrapping up

Oh guys we admitted it already in the results that the model is more or less crappy as far as predicting precise scores. This reflects the complexity of the issue and the incredible amount of randomness in the result: who would have bet that Roma would have won against Livelpool 4-2? Maybe it's better if we go back to the old school way (i.e. applying for grants) rather than trying to fund our future Post-docs with money won gambling. 

Of course, we could always try to improve predictions by introducing a temporal structure within the season, or using data from previous seasons to inform our priors or even use covariates (team budget, injuries, mean sexual appetite of players' girlfriend etc.) and so on and so forth. However this may not be a viable option for Champion's League results, where we have to deal with an additional complication: we hardly have any data on each team (at least in comparison to national Leagues, where each team plays with all the other teams of the League). Thus adding complexity here (read parameters) might not be the way to go (good luck fitting a 20 parameters model). This is exactly the case where fancier does not mean better predictions (turns out [Occam](https://simple.wikipedia.org/wiki/Occam%27s_razor) isn't just an excuse to show that statistician are not arid people but they have deep and philosophical interests as well). 

I bet you all think that this was a total waste of time from our sides. [We do not see it this way](https://en.wikipedia.org/wiki/Rationalization_(psychology)). As far as predicting the winner in fact, we were able to improve the 0.33 random guess probability prediction (at least for Real Madrid and the draw), and have a better idea of what's going to happen. A football Guru might argue that he could have done the same thing in the blink of an eye, silently using his prior knowledge. We are not here to meditate; we are here to provide scientific arguments based on teams' performance during Champion's League 2018. To put it another way, the time we spent on this project (roughly 20 hours) and the time we dedicated in watching any type of football during the past 5 years is at most 20 hours and 5 minutes (for all 3 of us). The time an average fan spends on watching football during 5 years is roughly 225 hours (assuming that one watched at least 20 matches of the team ones supports during the national leagues and at least 10 Champion's League matches per year, excluding Europa league, world and European cup). Thus, we gained the same knowledge (purely talking about predictions) than an average football fan using less that 10% of the time he needs to acquire this knowledge. 

Now back to our **GOAL** (oh my God it's still funny!):
Dad, if you came this far, I found some evidence that Real will win this year's Champion's league. If you bet and win, any contribution to the ISBA registration fees is highly appreciated, my supervisor is a bit short on cash.










